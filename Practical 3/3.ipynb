{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y7DABt6hwLxd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n",
      "Outliers detected in gender: 0\n",
      "Outliers detected in SeniorCitizen: 1142\n",
      "Outliers detected in Partner: 0\n",
      "Outliers detected in Dependents: 0\n",
      "Outliers detected in tenure: 0\n",
      "Outliers detected in PhoneService: 682\n",
      "Outliers detected in MultipleLines: 0\n",
      "Outliers detected in InternetService: 0\n",
      "Outliers detected in OnlineSecurity: 0\n",
      "Outliers detected in OnlineBackup: 0\n",
      "Outliers detected in DeviceProtection: 0\n",
      "Outliers detected in TechSupport: 0\n",
      "Outliers detected in StreamingTV: 0\n",
      "Outliers detected in StreamingMovies: 0\n",
      "Outliers detected in PaperlessBilling: 0\n",
      "Outliers detected in MonthlyCharges: 0\n",
      "Outliers detected in TotalCharges: 0\n",
      "Outliers detected in Churn: 0\n",
      "Outliers detected in Contract_One year: 1473\n",
      "Outliers detected in Contract_Two year: 1695\n",
      "Outliers detected in PaymentMethod_Credit card (automatic): 1522\n",
      "Outliers detected in PaymentMethod_Electronic check: 0\n",
      "Outliers detected in PaymentMethod_Mailed check: 1612\n",
      "Outliers detected in gender: 0\n",
      "Outliers detected in SeniorCitizen: 0\n",
      "Outliers detected in Partner: 0\n",
      "Outliers detected in Dependents: 0\n",
      "Outliers detected in tenure: 0\n",
      "Outliers detected in PhoneService: 0\n",
      "Outliers detected in MultipleLines: 0\n",
      "Outliers detected in InternetService: 0\n",
      "Outliers detected in OnlineSecurity: 0\n",
      "Outliers detected in OnlineBackup: 0\n",
      "Outliers detected in DeviceProtection: 0\n",
      "Outliers detected in TechSupport: 0\n",
      "Outliers detected in StreamingTV: 0\n",
      "Outliers detected in StreamingMovies: 0\n",
      "Outliers detected in PaperlessBilling: 0\n",
      "Outliers detected in MonthlyCharges: 0\n",
      "Outliers detected in TotalCharges: 0\n",
      "Outliers detected in Churn: 0\n",
      "Outliers detected in Contract_One year: 0\n",
      "Outliers detected in Contract_Two year: 0\n",
      "Outliers detected in PaymentMethod_Credit card (automatic): 0\n",
      "Outliers detected in PaymentMethod_Electronic check: 0\n",
      "Outliers detected in PaymentMethod_Mailed check: 0\n",
      "Training set size: (2507, 24)\n",
      "Testing set size: (627, 24)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data Cleaning and Preparation\n",
    "Problem Statement: Analyzing Customer Churn in a Telecommunications Company\n",
    "Dataset: \"Telecom_Customer_Churn.csv\"\n",
    "Description: The dataset contains information about customers of a telecommunications\n",
    "company and whether they have churned (i.e., discontinued their services). The dataset\n",
    "includes various attributes of the customers, such as their demographics, usage patterns, and\n",
    "account information. The goal is to perform data cleaning and preparation to gain insights\n",
    "into the factors that contribute to customer churn.\n",
    "Tasks to Perform:\n",
    "1. Import the \"Telecom_Customer_Churn.csv\" dataset.\n",
    "2. Explore the dataset to understand its structure and content.\n",
    "3. Handle missing values in the dataset, deciding on an appropriate strategy.\n",
    "4. Remove any duplicate records from the dataset.\n",
    "5. Check for inconsistent data, such as inconsistent formatting or spelling variations,\n",
    "and standardize it.\n",
    "6. Convert columns to the correct data types as needed.\n",
    "7. Identify and handle outliers in the data.\n",
    "8. Perform feature engineering, creating new features that may be relevant to\n",
    "predicting customer churn.\n",
    "9. Normalize or scale the data if necessary.\n",
    "10. Split the dataset into training and testing sets for further analysis.\n",
    "11. Export the cleaned dataset for future analysis or modeling.\n",
    "'''\n",
    "None\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Import the \"Telecom_Customer_Churn.csv\" dataset.\n",
    "data = pd.read_csv('Telco-Customer-Churn.csv')\n",
    "data\n",
    "\n",
    "# 2. Explore the dataset to understand its structure and content.\n",
    "data.describe()\n",
    "\n",
    "data.shape\n",
    "\n",
    "data.info()\n",
    "\n",
    "# 3. Handle missing values in the dataset, deciding on an appropriate strategy.\n",
    "data.isnull().sum()\n",
    "\n",
    "# 4. Remove any duplicate records from the dataset.\n",
    "data.duplicated().sum()\n",
    "\n",
    "# 5. Check for inconsistent data, such as inconsistent formatting or spelling variations,\n",
    "# and standardize it.\n",
    "data.columns\n",
    "\n",
    "# obj = StandardScaler()\n",
    "# data = data.target\n",
    "# data = obj.fit_transform(data)\n",
    "data\n",
    "\n",
    "# 6. Convert columns to the correct data types as needed.\n",
    "# gender_mapping = {'Male': 1, 'Female': 0}\n",
    "# Partner_mapping = {'Yes': 1, 'No': 0}\n",
    "# Dependents_mapping = {'Yes': 1, 'No': 0}\n",
    "# PhoneService_mapping = {'Yes': 1, 'No': 0}\n",
    "# MultipleLines_mapping = {'No phone service': 1, 'No': 0}\n",
    "# PhoneService_mapping = {'Yes': 1, 'No': 0}\n",
    "# MultipleLines_mapping = {'No phone service': 0, 'No': 0,'Yes':1}\n",
    "\n",
    "\n",
    "# data['gender'] = data['gender'].map(gender_mapping)\n",
    "\n",
    "data = data.drop(columns=['customerID'])\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# Convert 'Yes'/'No' binary columns using LabelBinarizer\n",
    "binary_columns = ['Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "                  'OnlineSecurity', 'DeviceProtection', 'TechSupport', \n",
    "                  'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Churn','OnlineBackup']\n",
    "\n",
    "for col in binary_columns:\n",
    "    data[col] = lb.fit_transform(data[col])\n",
    "\n",
    "# Encode 'gender' as 1 for 'Female' and 0 for 'Male'\n",
    "data['gender'] = lb.fit_transform(data['gender'])\n",
    "\n",
    "# Convert 'InternetService' to numerical values\n",
    "data['InternetService'] = data['InternetService'].map({'DSL': 1, 'Fiber optic': 2, 'No': 0})\n",
    "\n",
    "# Convert 'Contract' and 'PaymentMethod' using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['Contract', 'PaymentMethod'], drop_first=True)\n",
    "\n",
    "# Convert 'TotalCharges' to numeric, handle errors due to empty strings\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
    "\n",
    "binary_columns_new = ['Contract_One year','Contract_Two year','PaymentMethod_Credit card (automatic)','PaymentMethod_Electronic check','PaymentMethod_Mailed check']\n",
    "\n",
    "for col in binary_columns_new:\n",
    "    data[col] = lb.fit_transform(data[col])\n",
    "data\n",
    "\n",
    "data.dtypes\n",
    "\n",
    "# 7. Identify and handle outliers in the data.\n",
    "numeric_columns = data.columns\n",
    "\n",
    "for col in numeric_columns:\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Filter out rows with outliers\n",
    "    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
    "    print(f'Outliers detected in {col}: {len(outliers)}')\n",
    "\n",
    "    # handling outliers\n",
    "for col in numeric_columns:\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Remove outliers\n",
    "    data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n",
    "    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
    "    print(f'Outliers detected in {col}: {len(outliers)}')\n",
    "\n",
    "    # 8. Perform feature engineering, creating new features that may be relevant to\n",
    "# predicting customer churn.\n",
    "def tenure_group(tenure):\n",
    "    if tenure <= 12:\n",
    "        return '0-1 year'\n",
    "    elif tenure <= 24:\n",
    "        return '1-2 years'\n",
    "    elif tenure <= 48:\n",
    "        return '2-4 years'\n",
    "    elif tenure <= 60:\n",
    "        return '4-5 years'\n",
    "    else:\n",
    "        return '5+ years'\n",
    "\n",
    "data['TenureGroup'] = data['tenure'].apply(tenure_group)\n",
    "data['ChargesRatio'] = data['TotalCharges'] / (data['MonthlyCharges'] + 1)  # Adding 1 to avoid division by zero\n",
    "data\n",
    "\n",
    "# 10. Split the dataset into training and testing sets for further analysis.\n",
    "# 11. Export the cleaned dataset for future analysis or modeling.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your target variable and features\n",
    "X = data.drop(columns=['Churn'])  # Features (drop 'Churn' as it’s the target)\n",
    "y = data['Churn']  # Target variable\n",
    "\n",
    "# Split the data (80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")\n",
    "\n",
    "data.to_csv('cleaned_churn_data.csv', index=False)\n",
    "\n",
    "# Optionally, export training and testing sets separately\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Normalize or scale the data if necessary(Not required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
